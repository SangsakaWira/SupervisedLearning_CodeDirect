{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1N9GunQ5kSDA"
   },
   "source": [
    "# IRIS CLASSIFICATION\n",
    "Hari ini kita akan memodelkan AI berbasis DNN untuk mengklasifikasikan spesies bunga. Dengan Input sebanyak 4 dan output sebanyak 3\n",
    "\n",
    "**Kelas:**\n",
    "1. sepal length\n",
    "2. sepal width\n",
    "3. petal length\n",
    "4. petal width\n",
    "\n",
    "**Target:**\n",
    "1. Setosa\n",
    "2. Virginica\n",
    "3. Versicolor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHGeiVDtkRTC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "yT0f9V31Ziwl",
    "outputId": "f928420f-75fe-4e10-c3f8-2248644e95bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-25 06:17:01--  https://raw.githubusercontent.com/theo123490/basic_python_to_DNN_Tutorials/master/iris.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975 (3.9K) [text/plain]\n",
      "Saving to: ‘iris.csv.1’\n",
      "\n",
      "\r",
      "iris.csv.1            0%[                    ]       0  --.-KB/s               \r",
      "iris.csv.1          100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-10-25 06:17:02 (76.8 MB/s) - ‘iris.csv.1’ saved [3975/3975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/theo123490/basic_python_to_DNN_Tutorials/master/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbhobcNKZk1a"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IWlPX13_Zr3b",
    "outputId": "bededc51-c02d-4eff-f6a6-ab7c632118b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"variety\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LihGp5uHZs5H"
   },
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, :4]\n",
    "y = pd.get_dummies(dataset[\"variety\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "RQ5Ivos6kB4W",
    "outputId": "66c60f1a-22ca-45e6-d12e-24e51d5f3b40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Setosa</th>\n",
       "      <th>Versicolor</th>\n",
       "      <th>Virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Setosa  Versicolor  Virginica\n",
       "0         1           0          0\n",
       "1         1           0          0\n",
       "2         1           0          0\n",
       "3         1           0          0\n",
       "4         1           0          0\n",
       "..      ...         ...        ...\n",
       "145       0           0          1\n",
       "146       0           0          1\n",
       "147       0           0          1\n",
       "148       0           0          1\n",
       "149       0           0          1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJKS9UA3cHPX"
   },
   "outputs": [],
   "source": [
    "# SPLIT DATA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLarle44cNmi"
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wrhAonFPcQjz",
    "outputId": "b5595cb5-96d4-459f-bd28-0feb5bd58e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.0986 - acc: 0.3333 - val_loss: 1.0994 - val_acc: 0.2444\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 286us/step - loss: 1.0981 - acc: 0.3714 - val_loss: 1.0994 - val_acc: 0.2444\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 269us/step - loss: 1.0919 - acc: 0.3714 - val_loss: 1.0864 - val_acc: 0.2444\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 250us/step - loss: 1.0059 - acc: 0.4762 - val_loss: 0.9947 - val_acc: 0.5333\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 252us/step - loss: 0.8340 - acc: 0.6952 - val_loss: 0.9614 - val_acc: 0.6000\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 291us/step - loss: 0.6993 - acc: 0.6952 - val_loss: 0.5705 - val_acc: 0.6444\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 251us/step - loss: 0.4165 - acc: 0.7905 - val_loss: 0.3013 - val_acc: 0.9778\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 296us/step - loss: 0.3248 - acc: 0.8381 - val_loss: 0.2474 - val_acc: 0.8667\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 290us/step - loss: 0.2476 - acc: 0.8952 - val_loss: 0.2774 - val_acc: 0.8444\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 307us/step - loss: 0.1592 - acc: 0.9524 - val_loss: 0.2197 - val_acc: 0.9333\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 0.1634 - acc: 0.9429 - val_loss: 0.2955 - val_acc: 0.8444\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 349us/step - loss: 0.2026 - acc: 0.9048 - val_loss: 0.2951 - val_acc: 0.8444\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 299us/step - loss: 0.1161 - acc: 0.9524 - val_loss: 0.1181 - val_acc: 0.9778\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.1159 - acc: 0.9714 - val_loss: 0.0966 - val_acc: 0.9778\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.1278 - acc: 0.9619 - val_loss: 0.1177 - val_acc: 0.9333\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 317us/step - loss: 0.0841 - acc: 0.9619 - val_loss: 0.1226 - val_acc: 0.9333\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 349us/step - loss: 0.1677 - acc: 0.9333 - val_loss: 0.0850 - val_acc: 0.9778\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 317us/step - loss: 0.0970 - acc: 0.9619 - val_loss: 0.1323 - val_acc: 0.9778\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 281us/step - loss: 0.1392 - acc: 0.9333 - val_loss: 0.0845 - val_acc: 0.9333\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 0.0650 - acc: 0.9810 - val_loss: 0.0921 - val_acc: 0.9778\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 325us/step - loss: 0.0534 - acc: 0.9619 - val_loss: 0.0827 - val_acc: 0.9778\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 319us/step - loss: 0.0540 - acc: 0.9810 - val_loss: 0.1447 - val_acc: 0.9556\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 324us/step - loss: 0.0708 - acc: 0.9524 - val_loss: 0.1335 - val_acc: 0.9778\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 296us/step - loss: 0.0634 - acc: 0.9714 - val_loss: 0.4027 - val_acc: 0.8667\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 267us/step - loss: 0.2567 - acc: 0.8952 - val_loss: 0.3098 - val_acc: 0.8667\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 302us/step - loss: 0.2052 - acc: 0.9333 - val_loss: 0.4079 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 0.1812 - acc: 0.9143 - val_loss: 0.1428 - val_acc: 0.9556\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 0.1897 - acc: 0.9238 - val_loss: 0.0967 - val_acc: 0.9778\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 336us/step - loss: 0.0848 - acc: 0.9810 - val_loss: 0.1802 - val_acc: 0.9333\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 339us/step - loss: 0.1148 - acc: 0.9524 - val_loss: 0.0839 - val_acc: 0.9556\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 315us/step - loss: 0.1119 - acc: 0.9619 - val_loss: 0.2079 - val_acc: 0.9111\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 288us/step - loss: 0.1651 - acc: 0.9238 - val_loss: 0.2730 - val_acc: 0.8667\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 0.0951 - acc: 0.9714 - val_loss: 0.0861 - val_acc: 0.9778\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 330us/step - loss: 0.1200 - acc: 0.9619 - val_loss: 0.1163 - val_acc: 0.9333\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 326us/step - loss: 0.0750 - acc: 0.9619 - val_loss: 0.1527 - val_acc: 0.9556\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 305us/step - loss: 0.0430 - acc: 0.9905 - val_loss: 0.1202 - val_acc: 0.9333\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 326us/step - loss: 0.1433 - acc: 0.9524 - val_loss: 0.1136 - val_acc: 0.9778\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 302us/step - loss: 0.0601 - acc: 0.9714 - val_loss: 0.1094 - val_acc: 0.9778\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 322us/step - loss: 0.0608 - acc: 0.9619 - val_loss: 0.0998 - val_acc: 0.9778\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0640 - acc: 0.9714 - val_loss: 0.0964 - val_acc: 0.9778\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 0.0478 - acc: 0.9905 - val_loss: 0.1429 - val_acc: 0.9778\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 326us/step - loss: 0.1082 - acc: 0.9524 - val_loss: 0.1088 - val_acc: 0.9333\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 320us/step - loss: 0.1029 - acc: 0.9619 - val_loss: 0.0803 - val_acc: 0.9778\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 346us/step - loss: 0.0925 - acc: 0.9619 - val_loss: 0.2448 - val_acc: 0.9333\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 291us/step - loss: 0.0831 - acc: 0.9810 - val_loss: 0.0806 - val_acc: 0.9778\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 318us/step - loss: 0.0569 - acc: 0.9714 - val_loss: 0.0798 - val_acc: 0.9778\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 326us/step - loss: 0.0480 - acc: 0.9905 - val_loss: 0.1219 - val_acc: 0.9778\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 359us/step - loss: 0.0542 - acc: 0.9714 - val_loss: 0.0792 - val_acc: 0.9778\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 298us/step - loss: 0.0594 - acc: 0.9714 - val_loss: 0.0799 - val_acc: 0.9556\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 321us/step - loss: 0.1126 - acc: 0.9333 - val_loss: 0.1946 - val_acc: 0.9333\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 368us/step - loss: 0.0587 - acc: 0.9810 - val_loss: 0.0938 - val_acc: 0.9778\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 327us/step - loss: 0.0463 - acc: 0.9810 - val_loss: 0.1360 - val_acc: 0.9778\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 321us/step - loss: 0.0570 - acc: 0.9714 - val_loss: 0.1296 - val_acc: 0.9333\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 292us/step - loss: 0.3351 - acc: 0.9048 - val_loss: 0.8279 - val_acc: 0.7111\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 292us/step - loss: 0.1299 - acc: 0.9619 - val_loss: 0.1048 - val_acc: 0.9556\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 0.0846 - acc: 0.9714 - val_loss: 0.0887 - val_acc: 0.9778\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 0.0586 - acc: 0.9810 - val_loss: 0.0939 - val_acc: 0.9778\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 311us/step - loss: 0.0514 - acc: 0.9810 - val_loss: 0.0880 - val_acc: 0.9778\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 282us/step - loss: 0.0419 - acc: 0.9905 - val_loss: 0.1381 - val_acc: 0.9778\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 334us/step - loss: 0.1218 - acc: 0.9333 - val_loss: 0.2465 - val_acc: 0.9333\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 301us/step - loss: 0.2885 - acc: 0.9143 - val_loss: 0.2018 - val_acc: 0.9333\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 350us/step - loss: 0.1876 - acc: 0.9429 - val_loss: 0.3429 - val_acc: 0.8444\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 337us/step - loss: 0.2392 - acc: 0.9238 - val_loss: 0.2208 - val_acc: 0.8889\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 305us/step - loss: 0.1206 - acc: 0.9524 - val_loss: 0.0991 - val_acc: 0.9778\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 302us/step - loss: 0.0698 - acc: 0.9905 - val_loss: 0.1338 - val_acc: 0.9556\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 298us/step - loss: 0.0494 - acc: 0.9810 - val_loss: 0.1091 - val_acc: 0.9333\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 284us/step - loss: 0.1296 - acc: 0.9429 - val_loss: 0.0885 - val_acc: 0.9778\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 270us/step - loss: 0.1668 - acc: 0.9238 - val_loss: 0.2663 - val_acc: 0.8889\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 310us/step - loss: 0.1151 - acc: 0.9524 - val_loss: 0.1544 - val_acc: 0.9333\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 307us/step - loss: 0.0826 - acc: 0.9714 - val_loss: 0.1113 - val_acc: 0.9778\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 377us/step - loss: 0.0737 - acc: 0.9524 - val_loss: 0.0981 - val_acc: 0.9778\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 341us/step - loss: 0.0617 - acc: 0.9524 - val_loss: 0.1403 - val_acc: 0.9556\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 297us/step - loss: 0.0611 - acc: 0.9714 - val_loss: 0.0820 - val_acc: 0.9778\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0508 - acc: 0.9810 - val_loss: 0.1327 - val_acc: 0.9778\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 310us/step - loss: 0.0820 - acc: 0.9619 - val_loss: 0.0868 - val_acc: 0.9333\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 310us/step - loss: 0.0688 - acc: 0.9714 - val_loss: 0.1682 - val_acc: 0.9556\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 0.0663 - acc: 0.9524 - val_loss: 0.0807 - val_acc: 0.9778\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 318us/step - loss: 0.0770 - acc: 0.9714 - val_loss: 0.0795 - val_acc: 0.9778\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 344us/step - loss: 0.0531 - acc: 0.9905 - val_loss: 0.1409 - val_acc: 0.9556\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 336us/step - loss: 0.0674 - acc: 0.9714 - val_loss: 0.0810 - val_acc: 0.9778\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 277us/step - loss: 0.0509 - acc: 0.9810 - val_loss: 0.1365 - val_acc: 0.9778\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 414us/step - loss: 0.0513 - acc: 0.9810 - val_loss: 0.0826 - val_acc: 0.9556\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 303us/step - loss: 0.0525 - acc: 0.9810 - val_loss: 0.1155 - val_acc: 0.9778\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 284us/step - loss: 0.0567 - acc: 0.9619 - val_loss: 0.0815 - val_acc: 0.9778\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 0.0365 - acc: 0.9810 - val_loss: 0.1078 - val_acc: 0.9778\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0992 - acc: 0.9619 - val_loss: 0.1363 - val_acc: 0.9778\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 348us/step - loss: 0.1218 - acc: 0.9714 - val_loss: 0.1096 - val_acc: 0.9333\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 316us/step - loss: 0.0750 - acc: 0.9619 - val_loss: 0.1816 - val_acc: 0.9333\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 270us/step - loss: 0.0638 - acc: 0.9714 - val_loss: 0.1265 - val_acc: 0.9333\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0727 - acc: 0.9714 - val_loss: 0.1902 - val_acc: 0.9333\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 312us/step - loss: 0.0914 - acc: 0.9524 - val_loss: 0.1105 - val_acc: 0.9778\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 320us/step - loss: 0.0737 - acc: 0.9714 - val_loss: 0.0829 - val_acc: 0.9333\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 309us/step - loss: 0.0623 - acc: 0.9810 - val_loss: 0.1651 - val_acc: 0.9556\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 302us/step - loss: 0.0824 - acc: 0.9619 - val_loss: 0.0799 - val_acc: 0.9778\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 330us/step - loss: 0.1315 - acc: 0.9524 - val_loss: 0.2309 - val_acc: 0.9333\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 324us/step - loss: 0.1684 - acc: 0.9333 - val_loss: 0.0877 - val_acc: 0.9778\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0704 - acc: 0.9714 - val_loss: 0.0842 - val_acc: 0.9778\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 368us/step - loss: 0.0486 - acc: 0.9905 - val_loss: 0.0832 - val_acc: 0.9778\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0477 - acc: 0.9810 - val_loss: 0.0926 - val_acc: 0.9778\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 298us/step - loss: 0.0437 - acc: 0.9714 - val_loss: 0.0803 - val_acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a0aa9b198>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkq4w-pZc0ru"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IRIS Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
